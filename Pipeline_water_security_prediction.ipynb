{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4601561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.impute import KNNImputer\n",
    "from numpy import mean, logspace, min, max, meshgrid, linspace, c_, sqrt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors._classification import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8817d",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e144ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessing:\n",
    "\n",
    "    def __init__(self, dataframe2016, dataframe2020, index2016, index2020):\n",
    "        self.df2016 = pd.read_csv(dataframe2016)\n",
    "        self.df2020 = pd.read_csv(dataframe2020)\n",
    "        self.df_coordinate = pd.read_csv(\"./data/coordinates.csv\")\n",
    "\n",
    "        self.df2016 = pd.merge(self.df2016, self.df_coordinate, how='left', on='country')\n",
    "        self.df2020 = pd.merge(self.df2020, self.df_coordinate, how='left', on='country')\n",
    "\n",
    "        self.df_index2016 = pd.read_csv(index2016)\n",
    "        self.df_index2020 = pd.read_csv(index2020)\n",
    "\n",
    "        self.output_name = None\n",
    "\n",
    "\n",
    "\n",
    "    def replace(self):\n",
    "        self.df2016 = self.df2016[self.df2016.isna().sum(axis=1) < 19]\n",
    "        self.df2016.replace({'0': np.nan})\n",
    "\n",
    "        self.df2020 = self.df2020[self.df2020.isna().sum(axis=1) < 19]\n",
    "        self.df2020.replace({'0': np.nan})\n",
    "\n",
    "    def drop(self):\n",
    "         threshold2016 = self.df2016.shape[0] * 0.55\n",
    "         self.df2016.dropna(axis=\"columns\", thresh=threshold2016, inplace=True)\n",
    "         self.df2016.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "         threshold2020 = self.df2020.shape[0] * 0.55\n",
    "         self.df2020.dropna(axis=\"columns\", thresh=threshold2020, inplace=True)\n",
    "         self.df2020.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    def fill_na(self):\n",
    "        imputer = KNNImputer(n_neighbors=8)\n",
    "        length = len(self.df2016.columns)\n",
    "        self.df2016.iloc[:, 2:length] = imputer.fit_transform(self.df2016.iloc[:, 2:length])\n",
    "\n",
    "        length = len(self.df2020.columns)\n",
    "        self.df2020.iloc[:, 2:length] = imputer.fit_transform(self.df2020.iloc[:, 2:length])\n",
    "\n",
    "    def normalization(self):\n",
    "        length2016 = len(self.df2016.columns)\n",
    "        self.df2016.iloc[:,1:length2016] = self.df2016.iloc[:,1:length2016].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "        length2020 = len(self.df2020.columns)\n",
    "        self.df2020.iloc[:, 1:length2020] = self.df2020.iloc[:, 1:length2020].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "    def merge_index(self):\n",
    "         self.df2016 = pd.merge(self.df_index2016,self.df2016, on=\"country\", how=\"inner\")\n",
    "         self.df2020 = pd.merge(self.df_index2020,self.df2020,  on=\"country\", how=\"inner\")\n",
    "         self.df = self.df2020.append(self.df2016)\n",
    "\n",
    "         self.df.drop(\"country\", axis=1, inplace=True)\n",
    "         self.df.drop(\"Flood occurrence (WRI) (-)\", axis=1, inplace=True)\n",
    "\n",
    "    def write_2020data(self):\n",
    "        self.output_name2020 = \"./data/final data/\" + \"processed_data_2020\" + \".csv\"\n",
    "        self.df2020.to_csv(self.output_name2020)\n",
    "\n",
    "    def save(self, output_name, norm=True, write=True):\n",
    "        self.replace()\n",
    "        self.drop()\n",
    "        self.fill_na()\n",
    "        if norm:\n",
    "            self.normalization()\n",
    "        self.write_2020data()\n",
    "        self.merge_index()\n",
    "        if write:\n",
    "            self.output_name = \"./data/final data/\" + output_name + \".csv\"\n",
    "            self.df.to_csv(self.output_name)\n",
    "\n",
    "\n",
    "\n",
    "    def get_dataframe(self):\n",
    "        return pd.read_csv(self.output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2debfe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2016 = Preprocessing(\"./data/raw data/2016raw.csv\",\"./data/raw data/2020raw.csv\",\"./data/2016APindex.csv\",\"./data/2020APindex.csv\")\n",
    "data2016.save(\"newData\", norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5554ee2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d46d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split(x, y):\n",
    "    return train_test_split(x, y, test_size=0.33, random_state=0)\n",
    "\n",
    "\n",
    "class TreeModelBuilder:\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = pd.read_csv(dataframe)\n",
    "        self.df = self.dataframe.values\n",
    "        self.x = self.df[:, 2:]\n",
    "        self.y = self.df[:, 1].astype('float')\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = split(self.x, self.y)\n",
    "\n",
    "    def __building_model(self, x_train, y_train, model_type, number=1000):\n",
    "        if model_type == \"RD\":\n",
    "            classifier = RandomForestClassifier(n_estimators=number, random_state=0, n_jobs=-1)\n",
    "        elif model_type == \"Bagging\":\n",
    "            classifier = BaggingClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)\n",
    "        elif model_type == \"ADA\":\n",
    "            classifier = AdaBoostClassifier(n_estimators=1000, learning_rate=1).fit(x_train, y_train)\n",
    "        else:\n",
    "            classifier = GradientBoostingClassifier(n_estimators=number, learning_rate=1, max_depth=1, random_state=0)\n",
    "        return classifier.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    def __rebuild_model(self, model, model_type, number=0.05):\n",
    "        rebuild = SelectFromModel(model, threshold=number).fit(self.x_train, self.y_train)\n",
    "        x_important_train, x_important_test = rebuild.transform(self.x_train), rebuild.transform(self.x_test)\n",
    "        rebuild = self.__building_model(x_important_train, self.y_train, model_type=model_type, number=1000)\n",
    "        prediction = rebuild.predict(x_important_test)\n",
    "        return rebuild, prediction\n",
    "\n",
    "    def __get_score(self, model):\n",
    "        return model.score(self.x_test, self.y_test)\n",
    "\n",
    "    def __get_accuracy(self, prediction):\n",
    "        return accuracy_score(self.y_test, prediction)\n",
    "\n",
    "    def important_features(self, model):\n",
    "        results = model.feature_importances_\n",
    "        for i in range(len(self.df.columns[2:])):\n",
    "            print(self.df.columns[i] + results[i] + \"\\n\")\n",
    "\n",
    "    def save_plot(self, model):\n",
    "        plt.subplots(2, 2)\n",
    "        for i in range(0, 5):\n",
    "            fig = plt.figure(figsize=(20, 20))\n",
    "            tree.plot_tree(model.estimators_[i], feature_names=self.dataframe.columns[2:], filled=True, fontsize=10)\n",
    "            plt.show()\n",
    "\n",
    "    def decision_boundary(self):\n",
    "        model = self.__building_model(x_train=self.x_train, y_train=self.x_train, model_type=\"RD\")\n",
    "        x_train_reduced = TruncatedSVD(n_components=2, random_state=0).fit_transform(self.x_train)\n",
    "        prediction = model.predict(self.y_train)\n",
    "\n",
    "        x2d_x_min, x2d_x_max = min(x_train_reduced[:, 0]), max(x_train_reduced[:, 0])\n",
    "        x2d_y_min, x2d_y_max = min(x_train_reduced[:, 1]), max(x_train_reduced[:, 1])\n",
    "        xx, yy = meshgrid(linspace(x2d_x_min, x2d_x_max, 100), linspace(x2d_y_min, x2d_y_max, 100))\n",
    "\n",
    "        background_model = KNeighborsClassifier(n_neighbors=5).fit(x_train_reduced, prediction)\n",
    "        voronoi_background = background_model.predict(c_[xx.ravel(), yy.ravel()]).reshape((100, 100))\n",
    "\n",
    "        plt.contourf(xx, yy, voronoi_background)\n",
    "        plt.scatter(x_train_reduced[:, 0], x_train_reduced[:, 1], c=prediction)\n",
    "        plt.show()\n",
    "\n",
    "    def get_model(self, model_type, number=0.05, accuracy=False,rebuit=False):\n",
    "        if model_type == \"Boost\":\n",
    "            number = 0.01\n",
    "        model = self.__building_model(self.x_train, self.y_train, model_type=model_type)\n",
    "        if model_type != \"Bagging\" and model_type != \"ADA\":\n",
    "            rebuild_model = self.__rebuild_model(model, model_type=model_type, number=number)\n",
    "            if accuracy:\n",
    "                return [self.__get_score(model), self.__get_accuracy(rebuild_model[1])]\n",
    "            else:\n",
    "                return [model, rebuild_model[0]]\n",
    "        else:\n",
    "            if accuracy:\n",
    "                prediction = model.predict(self.x_test)\n",
    "                return [self.__get_score(model), self.__get_accuracy(prediction)]\n",
    "            else:\n",
    "                return [model]\n",
    "\n",
    "\n",
    "    def getrfrebuild(self,x=[],name=False):\n",
    "        model=RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1).fit(self.x_train, self.y_train)\n",
    "        rebuild1 = SelectFromModel(model, threshold=0.05).fit(self.x_train, self.y_train)\n",
    "        x_important_train, x_important_test = rebuild1.transform(self.x_train), rebuild1.transform(self.x_test)\n",
    "        rebuild = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1).fit(x_important_train, self.y_train)\n",
    "        featureindex=rebuild1.get_support(indices=True)\n",
    "        featurename=self.dataframe.columns[featureindex+2]\n",
    "        if len(x)!=0:\n",
    "            prediction = rebuild.predict(x)\n",
    "        if name:\n",
    "            return featurename\n",
    "        else:\n",
    "            return prediction\n",
    "    \n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "class SupportVectorMachineBuilder:\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = pd.read_csv(dataframe)\n",
    "        self.y = self.df['water security index']\n",
    "        self.x = self.df.iloc[:, 2:]\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = split(self.x, self.y)\n",
    "        self.model = None\n",
    "\n",
    "    def __build_model(self, c=None, gamma=None, tuning=False):\n",
    "        if tuning:\n",
    "            clf = svm.SVC(decision_function_shape='ovo', C=c, gamma=gamma)\n",
    "        else:\n",
    "            clf = svm.SVC(decision_function_shape='ovo')\n",
    "        model = clf.fit(self.x_train, self.y_train)\n",
    "        return model\n",
    "\n",
    "    def __tuning_model(self):\n",
    "        pipe = Pipeline([(\"svc\", self.__build_model())])\n",
    "        grid_parameters = {\n",
    "            'svc__C': [2 ** x for x in range(-5, 13)],\n",
    "            'svc__gamma': [2 ** x for x in range(-12, 4)]\n",
    "        }\n",
    "        grid = GridSearchCV(pipe, param_grid=grid_parameters,\n",
    "                            cv=3, scoring=make_scorer(f1_score, average=\"weighted\"), n_jobs=2,\n",
    "                            return_train_score=True, verbose=3)\n",
    "        grid.fit(self.x_train, self.y_train)\n",
    "        best_parameters = [grid.best_params_.get(\"svc__C\"), grid.best_params_.get(\"svc__gamma\")]\n",
    "        rebuild_model = self.__build_model(best_parameters[0], best_parameters[1], tuning=True)\n",
    "        return rebuild_model\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        accuracy_score_not_tuned = self.__build_model().score(self.x_test, self.y_test)\n",
    "        accuracy_score_tuned = self.__tuning_model().score(self.x_test, self.y_test)\n",
    "        return str(\"Results of model: \" + str(accuracy_score_not_tuned) + \"\\n\" +\n",
    "                   \"Results of tuned model:\" + str(accuracy_score_tuned))\n",
    "\n",
    "\n",
    "class RidgeLassoBuilder:\n",
    "\n",
    "    def __init__(self, dataframe, alpha):\n",
    "        self.df = pd.read_csv(dataframe).values\n",
    "        self.x = self.df[:, 2:self.df.shape[1]]\n",
    "        self.y = self.df[:, 1].astype('float')\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = split(self.x, self.y)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __building_model(self):\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
    "        if self.alpha == 0:\n",
    "            model = RidgeCV(alphas=logspace(-4, -0.5, 30), cv=cv)\n",
    "        else:\n",
    "            model = LassoCV(alphas=logspace(-4, -0.5, 30), cv=cv)\n",
    "        model = model.fit(self.x_train, self.y_train)\n",
    "        scores = cross_val_score(model, self.x_train, self.y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        prediction = [round(x, 0) for x in list(model.predict(self.x_test))]\n",
    "        return [mean(scores), accuracy_score(self.y_test, prediction)]\n",
    "\n",
    "    def get_plots_ridge_alpha(self):\n",
    "        alphas = logspace(-10, -2, 30)\n",
    "        coefs = []\n",
    "        for a in alphas:\n",
    "            ridge = Ridge(alpha=a, fit_intercept=False)\n",
    "            ridge.fit(self.x_train, self.y_train)\n",
    "            coefs.append(ridge.coef_)\n",
    "\n",
    "        plot = plt.gca()\n",
    "        plot.plot(alphas, coefs)\n",
    "        plot.set_xscale('log')\n",
    "        plot.set_xlim(plot.get_xlim()[::-1])\n",
    "        plt.xlabel('Alpha')\n",
    "        plt.ylabel('Weights')\n",
    "        plt.title('Ridge coefficients as a function of the regularization')\n",
    "        plt.axis('tight')\n",
    "        plt.show()\n",
    "\n",
    "    def get_plots_ridge_cv(self):\n",
    "        model = Lasso(random_state=0, max_iter=10000)\n",
    "        alphas = logspace(-4, -0.5, 30)\n",
    "        tuned_parameters = [{'alpha': alphas}]\n",
    "        model = GridSearchCV(model, tuned_parameters, cv=5, refit=False)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        scores = model.cv_results_['mean_test_score']\n",
    "        scores_std = model.cv_results_['std_test_score']\n",
    "        std_error = scores_std / sqrt(5)\n",
    "\n",
    "        plt.figure().set_size_inches(8, 6)\n",
    "        plt.semilogx(alphas, scores)\n",
    "        plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "        plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "        plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "        plt.ylabel('CV score +/- std error')\n",
    "        plt.xlabel('alpha')\n",
    "        plt.axhline(max(scores), linestyle='--', color='.5')\n",
    "        plt.xlim([alphas[0], alphas[-1]])\n",
    "        plt.show()\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        results = self.__building_model()\n",
    "        return str(\"Prediction \" + str(results[1]) + \"\\n\" +\n",
    "                   \"Accuracy based CV:\" + str(results[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22297ec4",
   "metadata": {},
   "source": [
    "## Model 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e7325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#predict the index of 2025\n",
    "mod1=TreeModelBuilder('./data/final data/newData.csv')\n",
    "\n",
    "featurename=mod1.getrfrebuild(name=True)\n",
    "print(featurename)\n",
    "\n",
    "\n",
    "print(mod1.get_model(\"Boost\", accuracy=True))\n",
    "print(mod1.get_model(\"Bagging\", accuracy=True))\n",
    "print(mod1.get_model(\"ADA\", accuracy=True))\n",
    "mod2 = SupportVectorMachineBuilder('./data/final data/newData.csv')\n",
    "print(mod2.get_accuracy())\n",
    "mod3 = RidgeLassoBuilder('./data/final data/newData.csv', 0)\n",
    "print(mod3.get_accuracy())\n",
    "print(mod1.get_model(\"RD\", accuracy=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all2020=pd.read_csv(\"./data/final data/processed_data_2020.csv\")\n",
    "x2020=all2020[featurename]\n",
    "y=mod1.getrfrebuild(x=x2020,name=False)\n",
    "all2020[\"water security index\"]=y\n",
    "all2020.to_csv(\"allindex2020.csv\")\n",
    "\n",
    "\n",
    "#====================\n",
    "#Get all the variables of 2025\n",
    "\n",
    "\n",
    "df=pd.read_csv('./data/newaquastat.csv')\n",
    "df=df.dropna(axis=0)\n",
    "\n",
    "def extract(name):\n",
    "    data=df.loc[df['Variable Name']==name]\n",
    "    return data\n",
    "\n",
    "def get2025(name):\n",
    "    df_AWW=df.loc[df['Variable Name']==name]\n",
    "    area=df_AWW['Area']\n",
    "    area=list(set(area))\n",
    "    df_AWW2025=pd.DataFrame(columns=('Area',name))\n",
    "    for i in range(0,len(area)):\n",
    "        df_areai=df_AWW.loc[df_AWW['Area']==area[i]]\n",
    "        x=df_areai['Year']\n",
    "        y=df_areai['Value']\n",
    "        p=np.poly1d(np.polyfit(x,y,1))\n",
    "        predict=p(2025)\n",
    "        df_AWW2025=df_AWW2025.append(pd.DataFrame({'Area':[area[i]],name:[predict]}))\n",
    "    return df_AWW2025\n",
    "\n",
    "\n",
    "def mergeall(vv):\n",
    "    length=len(vv)\n",
    "    result=pd.merge(get2025(vv[0]),get2025(vv[1]),on=['Area'])\n",
    "    for i in range(2,length):\n",
    "        result=pd.merge(result,get2025(vv[i]),on=['Area'])\n",
    "    return result\n",
    "\n",
    "\n",
    "def getfromother(name11):\n",
    "    df_PA65=pd.read_csv(\"./data/other/\"+ name11+\".csv\",header=None)\n",
    "    df_PA65=df_PA65.dropna(axis=0)\n",
    "    x=pd.to_numeric(df_PA65.iloc[0,3:])\n",
    "    df_PA2025=pd.DataFrame(columns=('Area',name11))\n",
    "    for i in range(1,df_PA65.shape[0]):\n",
    "        y=pd.to_numeric(df_PA65.iloc[i,3:])\n",
    "        p=np.poly1d(np.polyfit(x,y,4))\n",
    "        predict=p(2025)\n",
    "        df_PA2025=df_PA2025.append(pd.DataFrame({'Area':[df_PA65.iloc[i,0]],name11:[predict]}))\n",
    "    return df_PA2025\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba6e9a",
   "metadata": {},
   "source": [
    "### Generate the results of the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85332922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "name1='GDP per capita (current US$/inhab)'\n",
    "name2='Agriculture, value added (% GDP) (%)'\n",
    "name3='Human Development Index (HDI) [highest = 1] (-)'\n",
    "name4='Agricultural water withdrawal as % of total water withdrawal (%)'\n",
    "name5='Total population with access to safe drinking-water (JMP) (%)'\n",
    "name6='Urban population with access to safe drinking-water (JMP) (%)'\n",
    "name7=\"Mortality rate, infant (per 1,000 live births)\"\n",
    "name8=\"Net official development assistance and official aid received (current US$)\"\n",
    "\n",
    "vv=[name1,name2,name3,name4,name5,name6]\n",
    "result1=mergeall(vv)\n",
    "result1=pd.merge(result1,getfromother(name8),on=['Area'])\n",
    "result1=pd.merge(result1,getfromother(name7),on=['Area'])\n",
    "\n",
    "result1.to_csv('variable_2025.csv')\n",
    "\n",
    "#using the model to predict the 2025 indexes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "newx=pd.read_csv(\"variable_2025.csv\")\n",
    "xx=newx.values[:,2:]\n",
    "yy=mod1.getrfrebuild(x=xx,name=False)\n",
    "newx[\"water security index\"]=yy\n",
    "newx.to_csv(\"allindex2025.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bf5f9",
   "metadata": {},
   "source": [
    "## Analysis about index and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis is to use the final output to gain some knowledge about the relationship with population related variables and index.\n",
    "sns.set_theme(style=\"dark\",palette=sns.color_palette(\"husl\",2))\n",
    "data=pd.read_csv(\"allindex2020.csv\",index_col=[0])\n",
    "data.isnull().sum()\n",
    "data=data.dropna()\n",
    "\n",
    "# Group index into two classes\n",
    "\n",
    "data['water security index']=data['water security index'].map({1:0,2:0,3:1,4:1})\n",
    "\n",
    "\n",
    "# To exclude the possibility of water stress to be the respond variable by looking at the correlation between it and the others.\n",
    "listpop=['Rural population (1000 inhab)', \n",
    "           'Urban population (1000 inhab)',\n",
    "           'Population density (inhab/km2)',\n",
    "           'Urban population with access to safe drinking-water (JMP) (%)',\n",
    "           'Rural population with access to safe drinking-water (JMP) (%)',\n",
    "           'Total population with access to safe drinking-water (JMP) (%)',\n",
    "           'population ages0-14',\n",
    "           'Population ages 65 and above (_ of total population)']\n",
    "data[listpop].corrwith(data['SDG 6.4.2. Water Stress (%)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae86676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see some difference from the mean value of 0 and 1 classes\n",
    "\n",
    "data[['Rural population (1000 inhab)', \n",
    "           'Urban population (1000 inhab)',\n",
    "           'Population density (inhab/km2)',\n",
    "           'Urban population with access to safe drinking-water (JMP) (%)',\n",
    "           'Rural population with access to safe drinking-water (JMP) (%)',\n",
    "           'Total population with access to safe drinking-water (JMP) (%)',\n",
    "           'population ages0-14',\n",
    "           'Population ages 65 and above (_ of total population)','water security index'\n",
    "     ]].groupby('water security index').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ca0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in listpop:\n",
    "    plt.figure(figsize=(9,6))\n",
    "    g1=data[data['water security index']==0][x].values\n",
    "    g2=data[data['water security index']==1][x].values\n",
    "    \n",
    "    plt.hist(g1,bins=50,label=\"index=0\",color='green',alpha=0.5)\n",
    "    plt.hist(g2,bins=50,label=\"index=1\",color='orange',alpha=0.5)\n",
    "    \n",
    "    # Two dot lines represent the mean of 0 and 1 group\n",
    "    g1_mean=g1.mean()\n",
    "    g2_mean=g2.mean()\n",
    "    plt.axvline(g1_mean,ls='--',c='green',linewidth=1)\n",
    "    plt.axvline(g2_mean,ls='--',c='orange',linewidth=1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Historgram by Different Index Group\\n{}\".format(x),fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa909c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use t.test to see the significance of variables\n",
    "\n",
    "for col in listpop:\n",
    "    \n",
    "    # Get the values of 0 and 1 seperately\n",
    "    g1=data[data['water security index']==0][col].values\n",
    "    g2=data[data['water security index']==1][col].values\n",
    "\n",
    "    p_levene=stats.levene(g1, g2)[1]\n",
    "    if p_levene>0.05:\n",
    "        statistic,pvalue_ttest=stats.ttest_ind(g1, g2, equal_var = True)\n",
    "    else:\n",
    "        statistic,pvalue_ttest=stats.ttest_ind(g1, g2, equal_var = False)\n",
    "        \n",
    "    print(\"{:<70}: ttest- statistic={:>10.5f};pvalue={:>10.5f}\".format(col,statistic,pvalue_ttest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217308d",
   "metadata": {},
   "source": [
    "+ The last five variables has significant influence on index classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a202f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the feature of random forest model to output feature importance\n",
    "# So here use random forest to build a classification model where x is the features and y is index\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(random_state=1)\n",
    "\n",
    "x_cols=listpop\n",
    "        \n",
    "x=data[x_cols]\n",
    "y=data['water security index']\n",
    "\n",
    "classifier.fit(x,y)\n",
    "feature_importances=classifier.feature_importances_\n",
    "\n",
    "df_feature_importances=pd.DataFrame(zip(x_cols,feature_importances),columns=[\"features\",\"importance\"])\n",
    "df_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the importance\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.barplot(x=\"features\",y=\"importance\",data=df_feature_importances)\n",
    "plt.xticks(rotation=-90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
